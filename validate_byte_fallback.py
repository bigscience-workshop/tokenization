from transformers import AutoTokenizer

hf_tokenizer = AutoTokenizer.from_pretrained('bigscience/oscar_13_languages_alpha_weight')

assert hf_tokenizer.decode(hf_tokenizer.encode('換金方法としてはコイン商への売却の他、')) == '換金方法としてはコイン商への売却の他、'
assert hf_tokenizer.tokenize('換金方法としてはコイン商への売却の他、') == ['換', '金', '方法', 'と', 'し', '<0xE3>', '<0x81>', '<0xA6>', '<0xE3>', '<0x81>', '<0xAF>', '<0xE3>', '<0x82>', '<0xB3>', '<0xE3>', '<0x82>', '<0xA4>', 'ン', '商', '<0xE3>', '<0x81>', '<0xB8>', 'の', '<0xE5>', '<0xA3>', '<0xB2>', '却', 'の', '他', '、']
assert hf_tokenizer.decode(hf_tokenizer.encode('ማንነቱ ያልታወቀው ረዳት ፓይለት ')) == 'ማንነቱ ያልታወቀው ረዳት ፓይለት '
assert hf_tokenizer.tokenize('ማንነቱ ያልታወቀው ረዳት ፓይለት ') == ['<0xE1>', '<0x88>', '<0x9B>', '<0xE1>', '<0x8A>', '<0x95>', '<0xE1>', '<0x8A>', '<0x90>', '<0xE1>', '<0x89>', '<0xB1>', '▁', '<0xE1>', '<0x8B>', '<0xAB>', '<0xE1>', '<0x88>', '<0x8D>', '<0xE1>', '<0x89>', '<0xB3>', '<0xE1>', '<0x8B>', '<0x88>', '<0xE1>', '<0x89>', '<0x80>', '<0xE1>', '<0x8B>', '<0x8D>', '▁', '<0xE1>', '<0x88>', '<0xA8>', '<0xE1>', '<0x8B>', '<0xB3>', '<0xE1>', '<0x89>', '<0xB5>', '▁', '<0xE1>', '<0x8D>', '<0x93>', '<0xE1>', '<0x8B>', '<0xAD>', '<0xE1>', '<0x88>', '<0x88>', '<0xE1>', '<0x89>', '<0xB5>', '▁']

expected = '''換金方法としてはコイン商への売却の他、
['換', '金', '方法', 'と', 'し', '<0xE3>', '<0x81>', '<0xA6>', '<0xE3>', '<0x81>', '<0xAF>', '<0xE3>', '<0x82>', '<0xB3>', '<0xE3>', '<0x82>', '<0xA4>', 'ン', '商', '<0xE3>', '<0x81>', '<0xB8>', 'の', '<0xE5>', '<0xA3>', '<0xB2>', '却', 'の', '他', '、']
ማንነቱ ያልታወቀው ረዳት ፓይለት 
['<0xE1>', '<0x88>', '<0x9B>', '<0xE1>', '<0x8A>', '<0x95>', '<0xE1>', '<0x8A>', '<0x90>', '<0xE1>', '<0x89>', '<0xB1>', '▁', '<0xE1>', '<0x8B>', '<0xAB>', '<0xE1>', '<0x88>', '<0x8D>', '<0xE1>', '<0x89>', '<0xB3>', '<0xE1>', '<0x8B>', '<0x88>', '<0xE1>', '<0x89>', '<0x80>', '<0xE1>', '<0x8B>', '<0x8D>', '▁', '<0xE1>', '<0x88>', '<0xA8>', '<0xE1>', '<0x8B>', '<0xB3>', '<0xE1>', '<0x89>', '<0xB5>', '▁', '<0xE1>', '<0x8D>', '<0x93>', '<0xE1>', '<0x8B>', '<0xAD>', '<0xE1>', '<0x88>', '<0x88>', '<0xE1>', '<0x89>', '<0xB5>', '▁']'''

print('You should see:')
print(expected)
print('\nActual:')
print(hf_tokenizer.decode(hf_tokenizer.encode('換金方法としてはコイン商への売却の他、')))
print(hf_tokenizer.tokenize('換金方法としてはコイン商への売却の他、'))
print(hf_tokenizer.decode(hf_tokenizer.encode('ማንነቱ ያልታወቀው ረዳት ፓይለት ')))
print(hf_tokenizer.tokenize('ማንነቱ ያልታወቀው ረዳት ፓይለት '))
